posteriors[[i]] <- compute_classifier(ccp_list, pp, unlist(X[i,]))
}
preds <- factor(lapply(posteriors, FUN=function(obs){return(which.max(obs) - 1)}) %>% as.vector(), levels =levels(y))
mis <- sum(y != preds)/length(y)
return(list(prp = pp,
ccp = setNames(ccp_list,names(X)),
post = posteriors,
pred = preds,
mis = mis))
}
out <- naive_bayes(newX, resp)
for(i in 1:5){
print(out$ccp[[i]])
}
for(i in 1:5){
print(names(newX)[i])
print(out$ccp[[i]])
}
named_ccp <- setNames(out$ccp, names(newX))
for(i in 1:5){
print(named_ccp[[i]])
}
named_ccp[[i]]
for(i in 1:5){
named_ccp[[i]]
}
named_ccp
for(i in 1:5){
cat(named_ccp[[i]])
}
lapply(out$ccp, FUN=function(cc){
print(cc)
})
out$ccp[1:5]
naive_bayes <- function(X, y){
if(!is.factor(y))
y <- as.factor(y)
output <- list() # list to be outputted in the end
pp <- prop.table(table(y)) # prior probabilities
ccp_list <- list() # Class conditional probabilities list
if(dim(X)[2] == 1){
ccp_list <- prop.table(table(y, X[,1]), margin=1)
}else{
for(i in 1:dim(X)[2]){
ccp_list[[i]] <- prop.table(table(y, X[,i]), margin=1)
}
}
ccp_list <- setNames(ccp_list, names(X))
# return(ccp_list)
posteriors <- list()
for(i in 1:nrow(X)){
posteriors[[i]] <- compute_classifier(ccp_list, pp, unlist(X[i,]))
}
preds <- factor(lapply(posteriors, FUN=function(obs){return(which.max(obs) - 1)}) %>% as.vector(), levels =levels(y))
mis <- sum(y != preds)/length(y)
return(list(prp = pp,
ccp = ccp_list,
post = posteriors,
pred = preds,
mis = mis))
}
out <- naive_bayes(newX, resp)
out$prp
out$ccp[1:5]
out$post[1:5]
out$pred[1:5]
out$mis
fit <- naiveBayes(X, resp)
fit
fit$apriori
pred <- predict(fit, newX)
fit <- naiveBayes(newX,resp)
pred <- predict(fit, newX)
sum(pred!= resp) / length(resp)
out$mis
spam_words <- spamnotlegit[1:50] # Top 20 exclusive spam words
ham_words <- legitnotspam[1:50] # Top 20 exclusive ham words
both_words <- wordVect # Top 20 spam appearing more than 30% of the time
wordSearch <- function(eml, vec){
email <- c()
for(i in seq_along(vec)){
# If word appears in email at least once, encode col/row as 1
if (sum(str_count(eml, paste(vec[i]))) >= 1){
email <- c(email, 1)
}
else{
email <- c(email, 0)
}
}
# Binding to global feature matrix X
X <<- rbind(X, email)
return(X)
}
vec <- c(spam_words, both_words, ham_words) # Using all 114 features
vec
X <<- data.frame(NULL)
for(i in 1:length(training.emails)){
wordSearch(training.emails[[i]], vec)
}
resp <- labels$V1  %>% as.factor() # Grabbing training labels
newX <- X[,-which(names(X) %in% c("Re", "00", "on"))] # Removing feature that gives us problems =(
out <- naive_bayes(newX, resp)
out <- naive_bayes(newX, resp)
newX <- X[,-which(names(X) %in% c("Re", "00", "on"))] # Removing feature that gives us problems =(
colnames(X) <- vec
newX <- X[,-which(names(X) %in% c("Re", "00", "on"))] # Removing feature that gives us problems =(
out <- naive_bayes(newX, resp)
naive_bayes <- function(X, y){
if(!is.factor(y))
y <- as.factor(y)
output <- list() # list to be outputted in the end
pp <- prop.table(table(y)) # prior probabilities
ccp_list <- list() # Class conditional probabilities list
if(dim(X)[2] == 1){
ccp_list <- prop.table(table(y, X[,1]), margin=1)
}else{
for(i in 1:dim(X)[2]){
ccp_list[[i]] <- prop.table(table(y, X[,i]), margin=1)
}
}
ccp_list <- setNames(ccp_list, names(X))
print(ccp_list)
# return(ccp_list)
posteriors <- list()
for(i in 1:nrow(X)){
posteriors[[i]] <- compute_classifier(ccp_list, pp, unlist(X[i,]))
}
preds <- factor(lapply(posteriors, FUN=function(obs){return(which.max(obs) - 1)}) %>% as.vector(), levels =levels(y))
mis <- sum(y != preds)/length(y)
return(list(prp = pp,
ccp = ccp_list,
post = posteriors,
pred = preds,
mis = mis))
}
out <- naive_bayes(newX, resp)
newX <- X[,-which(names(X) %in% c("Re", "00", "on", "20"))] # Removing feature that gives us problems =(
out <- naive_bayes(newX, resp)
out$prp
out$ccp[1:5]
out$post[1:5]
out$pred[1:5]
out$mis
spamMaster$word == "Unsubscribe" %>% which()
which(spamMaster$word == "Unsubscribe")
spamMaster[127,]
which(legitMaster$word == "Unsubscribe")
legitMaster[34,]
out$prior
out$prp
table(labels$V1)
out$mis
1 - out$mis
kfold_idxs <- sample(x = 1:10, replace = TRUE, size = length(resp))
kfold_idxs
naive_bayes <- function(X, y){
if(!is.factor(y))
y <- as.factor(y)
output <- list() # list to be outputted in the end
pp <- prop.table(table(y)) # prior probabilities
ccp_list <- list() # Class conditional probabilities list
if(dim(X)[2] == 1){
ccp_list <- prop.table(table(y, X[,1]), margin=1)
}else{
for(i in 1:dim(X)[2]){
ccp_list[[i]] <- prop.table(table(y, X[,i]), margin=1)
}
}
ccp_list <- setNames(ccp_list, names(X))
posteriors <- list()
for(i in 1:nrow(X)){
posteriors[[i]] <- compute_classifier(ccp_list, pp, unlist(X[i,]))
}
preds <- factor(lapply(posteriors, FUN=function(obs){return(which.max(obs) - 1)}) %>% as.vector(), levels =levels(y))
mis <- sum(y != preds)/length(y)
return(list(prp = pp,
ccp = ccp_list,
post = posteriors,
pred = preds,
mis = mis))
}
kfold_idxs <- sample(x = 1:10, replace = TRUE, size = length(resp))
miss_tr <- numeric(0)
miss_te <- numeric(0)
for(i in 1:k){
train <- which(kfold_idxs != i)
test <- -train
fit <- naive_bayes(X[train,], resp[train])
#Calculating current fold training missclass rate
miss_tr <- c(miss_class, fit$mis)
#Calculating test missclass
posteriors <- list()
X_test <- X[test,]
for(i in 1:nrow(X_test)){
posteriors[[i]] <- compute_classifier(ccp_list, pp, unlist(X_test[i,]))
}
preds <- factor(lapply(posteriors, FUN=function(obs){return(which.max(obs) - 1)}) %>% as.vector(), levels =levels(resp))
miss_te <- c(miss_te, sum(resp[test] != preds)/length(resp[test]))
}
miss_tr <- numeric(0)
miss_te <- numeric(0)
for(i in 1:10){
train <- which(kfold_idxs != i)
test <- -train
fit <- naive_bayes(X[train,], resp[train])
#Calculating current fold training missclass rate
miss_tr <- c(miss_class, fit$mis)
#Calculating test missclass
posteriors <- list()
X_test <- X[test,]
for(i in 1:nrow(X_test)){
posteriors[[i]] <- compute_classifier(ccp_list, pp, unlist(X_test[i,]))
}
preds <- factor(lapply(posteriors, FUN=function(obs){return(which.max(obs) - 1)}) %>% as.vector(), levels =levels(resp))
miss_te <- c(miss_te, sum(resp[test] != preds)/length(resp[test]))
}
for(i in 1:10){
train <- which(kfold_idxs != i)
test <- -train
print(i)
fit <- naive_bayes(X[train,], resp[train])
#Calculating current fold training missclass rate
miss_tr <- c(miss_class, fit$mis)
#Calculating test missclass
posteriors <- list()
X_test <- X[test,]
for(i in 1:nrow(X_test)){
posteriors[[i]] <- compute_classifier(ccp_list, pp, unlist(X_test[i,]))
}
preds <- factor(lapply(posteriors, FUN=function(obs){return(which.max(obs) - 1)}) %>% as.vector(), levels =levels(resp))
miss_te <- c(miss_te, sum(resp[test] != preds)/length(resp[test]))
}
train
length(train)
length(test)
dim(X[test,])
X[train,] %>% View()
miss_tr <- numeric(0)
miss_te <- numeric(0)
set.seed(1)
kfold_idxs <- sample(x = 1:10, replace = TRUE, size = length(resp))
miss_tr <- numeric(0)
miss_te <- numeric(0)
for(i in 1:10){
train <- which(kfold_idxs != i)
test <- -train
print(i)
fit <- naive_bayes(newX[train,], resp[train])
#Calculating current fold training missclass rate
miss_tr <- c(miss_class, fit$mis)
#Calculating test missclass
posteriors <- list()
X_test <- newX[test,]
for(i in 1:nrow(X_test)){
posteriors[[i]] <- compute_classifier(ccp_list, pp, unlist(X_test[i,]))
}
preds <- factor(lapply(posteriors, FUN=function(obs){return(which.max(obs) - 1)}) %>% as.vector(), levels =levels(resp))
miss_te <- c(miss_te, sum(resp[test] != preds)/length(resp[test]))
}
set.seed(1)
kfold_idxs <- sample(x = 1:10, replace = TRUE, size = length(resp))
miss_tr <- numeric(0)
miss_te <- numeric(0)
for(i in 1:10){
train <- which(kfold_idxs != i)
test <- -train
print(i)
fit <- naive_bayes(newX[train,], resp[train])
#Calculating current fold training missclass rate
miss_tr <- c(miss_tr, fit$mis)
#Calculating test missclass
posteriors <- list()
X_test <- newX[test,]
for(i in 1:nrow(X_test)){
posteriors[[i]] <- compute_classifier(ccp_list, pp, unlist(X_test[i,]))
}
preds <- factor(lapply(posteriors, FUN=function(obs){return(which.max(obs) - 1)}) %>% as.vector(), levels =levels(resp))
miss_te <- c(miss_te, sum(resp[test] != preds)/length(resp[test]))
}
set.seed(1)
kfold_idxs <- sample(x = 1:10, replace = TRUE, size = length(resp))
miss_tr <- numeric(0)
miss_te <- numeric(0)
for(i in 1:10){
train <- which(kfold_idxs != i)
test <- -train
print(i)
fit <- naive_bayes(newX[train,], resp[train])
#Calculating current fold training missclass rate
miss_tr <- c(miss_tr, fit$mis)
#Calculating test missclass
posteriors <- list()
X_test <- newX[test,]
for(i in 1:nrow(X_test)){
posteriors[[i]] <- compute_classifier(fit$ccp, fit$prp, unlist(X_test[i,]))
}
preds <- factor(lapply(posteriors, FUN=function(obs){return(which.max(obs) - 1)}) %>% as.vector(), levels =levels(resp))
miss_te <- c(miss_te, sum(resp[test] != preds)/length(resp[test]))
}
summary(miss_tr)
summary(miss_te)
ggplot() +
geom_boxplot(mapping=aes(x = coloring,
y = c(mses,mspes),
col = coloring), show.legend = FALSE) +
labs(x="Metric",
y="Measurement",
title="MSE and MSPE Using 10-Fold CV",
subtitle=paste("Avg MSE: ",
round(mean(miss_tr),3),
" | Avg MSPE: ",
round(mean(miss_te),3), sep="")) +
annotate(geom = "text", x = "MSE", y = median(miss_tr),
label=round(median(miss_tr), 3)) +
annotate(geom = "text", x = "MSPE", y = median(miss_te),
label=round(median(miss_te), 3))
library(ggplot2)
ggplot() +
geom_boxplot(mapping=aes(x = coloring,
y = c(mses,mspes),
col = coloring), show.legend = FALSE) +
labs(x="Metric",
y="Measurement",
title="MSE and MSPE Using 10-Fold CV",
subtitle=paste("Avg MSE: ",
round(mean(miss_tr),3),
" | Avg MSPE: ",
round(mean(miss_te),3), sep="")) +
annotate(geom = "text", x = "MSE", y = median(miss_tr),
label=round(median(miss_tr), 3)) +
annotate(geom = "text", x = "MSPE", y = median(miss_te),
label=round(median(miss_te), 3))
ggplot() +
geom_boxplot(mapping=aes(x = coloring,
y = c(mses,mspes),
col = c(rep("MSE",10),rep("MSPE",10)), show.legend = FALSE) +
labs(x="Metric",
y="Measurement",
title="MSE and MSPE Using 10-Fold CV",
subtitle=paste("Avg MSE: ",
round(mean(miss_tr),3),
" | Avg MSPE: ",
round(mean(miss_te),3), sep="")) +
annotate(geom = "text", x = "MSE", y = median(miss_tr),
label=round(median(miss_tr), 3)) +
annotate(geom = "text", x = "MSPE", y = median(miss_te),
label=round(median(miss_te), 3))
```
ggplot() +
geom_boxplot(mapping=aes(x = c(rep("MSE",10),rep("MSPE",10)),
y = c(miss_tr,miss_te),
col = c(rep("MSE",10),rep("MSPE",10)), show.legend = FALSE) +
labs(x="Metric",
y="Measurement",
title="MSE and MSPE Using 10-Fold CV",
subtitle=paste("Avg MSE: ",
round(mean(miss_tr),3),
" | Avg MSPE: ",
round(mean(miss_te),3), sep="")) +
annotate(geom = "text", x = "MSE", y = median(miss_tr),
label=round(median(miss_tr), 3)) +
annotate(geom = "text", x = "MSPE", y = median(miss_te),
label=round(median(miss_te), 3))
```
ggplot() +
geom_boxplot(mapping=aes(x = c(rep("MSE",10),rep("MSPE",10)),
y = c(miss_tr,miss_te),
col = c(rep("MSE",10),rep("MSPE",10)), show.legend = FALSE)
```
ggplot() +
geom_boxplot(mapping=aes(x = c(rep("MSE",10),rep("MSPE",10)),
y = c(miss_tr,miss_te),
col = c(rep("MSE",10),rep("MSPE",10)), show.legend = FALSE)) +
labs(x="Metric",
y="Measurement",
title="MSE and MSPE Using 10-Fold CV",
subtitle=paste("Avg MSE: ",
round(mean(miss_tr),3),
" | Avg MSPE: ",
round(mean(miss_te),3), sep="")) +
annotate(geom = "text", x = "MSE", y = median(miss_tr),
label=round(median(miss_tr), 3)) +
annotate(geom = "text", x = "MSPE", y = median(miss_te),
label=round(median(miss_te), 3))
ggplot() +
geom_boxplot(mapping=aes(x = c(rep("MSE",10),rep("MSPE",10)),
y = c(miss_tr,miss_te),
col = c(rep("MSE",10),rep("MSPE",10))), show.legend = FALSE) +
labs(x="Metric",
y="Measurement",
title="Train and Test Error Rate Using 10-Fold CV",
subtitle=paste("Avg Train Error: ",
round(mean(miss_tr),3),
" | Avg Test Error: ",
round(mean(miss_te),3), sep="")) +
annotate(geom = "text", x = "Train", y = median(miss_tr),
label=round(median(miss_tr), 3)) +
annotate(geom = "text", x = "Test", y = median(miss_te),
label=round(median(miss_te), 3))
ggplot() +
geom_boxplot(mapping=aes(x = c(rep("Train",10),rep("Test",10)),
y = c(miss_tr,miss_te),
col = c(rep("Train",10),rep("Test",10))), show.legend = FALSE) +
labs(x="Metric",
y="Measurement",
title="Train and Test Error Rate Using 10-Fold CV",
subtitle=paste("Avg Train Error: ",
round(mean(miss_tr),3),
" | Avg Test Error: ",
round(mean(miss_te),3), sep="")) +
annotate(geom = "text", x = "Train", y = median(miss_tr),
label=round(median(miss_tr), 3)) +
annotate(geom = "text", x = "Test", y = median(miss_te),
label=round(median(miss_te), 3))
miss_te
ggplot() +
geom_boxplot(mapping=aes(x = c(rep("Train",10),rep("Test",10)),
y = c(miss_tr,miss_te),
col = c(rep("Train",10),rep("Test",10))), show.legend = FALSE) +
labs(x="Metric",
y="Measurement",
title="Train and Test Error Rate Using 10-Fold CV",
subtitle=paste("Avg Train Error: ",
round(mean(miss_tr, na.rm = TRUE),3),
" | Avg Test Error: ",
round(mean(miss_te, na.rm = TRUE),3), sep="")) +
annotate(geom = "text", x = "Train", y = median(miss_tr),
label=round(median(miss_tr), 3)) +
annotate(geom = "text", x = "Test", y = median(miss_te),
label=round(median(miss_te), 3))
ggplot() +
geom_boxplot(mapping=aes(x = c(rep("Train",10),rep("Test",10)),
y = c(miss_tr,miss_te),
col = c(rep("Train",10),rep("Test",10))), show.legend = FALSE) +
labs(x="Metric",
y="Measurement",
title="Train and Test Error Rate Using 10-Fold CV",
subtitle=paste("Avg Train Error: ",
round(mean(miss_tr, na.rm = TRUE),3),
" | Avg Test Error: ",
round(mean(miss_te, na.rm = TRUE),3), sep="")) +
annotate(geom = "text", x = "Train", y = median(miss_tr, na.rm = TRUE),
label=round(median(miss_tr), 3)) +
annotate(geom = "text", x = "Test", y = median(miss_te, na.rm = TRUE),
label=round(median(miss_te), 3))
ggplot() +
geom_boxplot(mapping=aes(x = c(rep("Train",10),rep("Test",10)),
y = c(miss_tr,miss_te),
col = c(rep("Train",10),rep("Test",10))), show.legend = FALSE) +
labs(x="Metric",
y="Measurement",
title="Train and Test Error Rate Using 10-Fold CV",
subtitle=paste("Avg Train Error: ",
round(mean(miss_tr, na.rm = TRUE),3),
" | Avg Test Error: ",
round(mean(miss_te, na.rm = TRUE),3), sep="")) +
annotate(geom = "text", x = "Train", y = median(miss_tr, na.rm = TRUE),
label=round(median(miss_tr, na.rm = TRUE), 3)) +
annotate(geom = "text", x = "Test", y = median(miss_te, na.rm = TRUE),
label=round(median(miss_te, na.rm = TRUE), 3))
ggplot() +
geom_boxplot(mapping=aes(x = c(rep("Train",10),rep("Test",10)),
y = c(miss_tr,miss_te),
col = c(rep("Train",10),rep("Test",10))), show.legend = FALSE) +
labs(x="Metric",
y="Measurement",
title="Train and Test Error Rate Using 10-Fold CV",
subtitle=paste("Avg Train Error: ",
round(mean(miss_tr, na.rm = TRUE),3),
" | Avg Test Error: ",
round(mean(miss_te, na.rm = TRUE),3), sep="")) +
annotate(geom = "text", x = "Train", y = median(miss_tr, na.rm = TRUE),
label=round(median(miss_tr, na.rm = TRUE), 3)) +
annotate(geom = "text", x = "Test", y = median(miss_te, na.rm = TRUE),
label=round(median(miss_te, na.rm = TRUE), 3))
ggplot() +
geom_boxplot(mapping=aes(x = c(rep("Train",10),rep("Test",10)),
y = c(miss_tr,miss_te),
col = c(rep("Train",10),rep("Test",10))), show.legend = FALSE) +
labs(x="Subset Used To Evaluate",
y="Measurement",
title="Train and Test Error Rate Using 10-Fold CV",
subtitle=paste("Avg Train Error: ",
round(mean(miss_tr, na.rm = TRUE),3),
" | Avg Test Error: ",
round(mean(miss_te, na.rm = TRUE),3), sep="")) +
annotate(geom = "text", x = "Train", y = median(miss_tr, na.rm = TRUE),
label=round(median(miss_tr, na.rm = TRUE), 3)) +
annotate(geom = "text", x = "Test", y = median(miss_te, na.rm = TRUE),
label=round(median(miss_te, na.rm = TRUE), 3))
ggplot() +
geom_boxplot(mapping=aes(x = c(rep("Train",10),rep("Test",10)),
y = c(miss_tr,miss_te),
col = c(rep("Train",10),rep("Test",10))), show.legend = FALSE) +
labs(x="Partition of Data",
y="Measurement",
title="Train and Test Error Rate Using 10-Fold CV",
subtitle=paste("Avg Train Error: ",
round(mean(miss_tr, na.rm = TRUE),3),
" | Avg Test Error: ",
round(mean(miss_te, na.rm = TRUE),3), sep="")) +
annotate(geom = "text", x = "Train", y = median(miss_tr, na.rm = TRUE),
label=round(median(miss_tr, na.rm = TRUE), 3)) +
annotate(geom = "text", x = "Test", y = median(miss_te, na.rm = TRUE),
label=round(median(miss_te, na.rm = TRUE), 3))
sd(miss_te)
sd(miss_te,na.rm = TRUE)
sd(miss_tr)
1-0.052
mean(miss_te, na.rm=TRUE)
1 - mean(miss_te, na.rm=TRUE)
dim(newX)
